<!DOCTYPE html>
<html>
  <head>
    <title>A-Frame / WebXR / AR / Hit Test with Hand Tracking</title>
    <meta name="description" content="Hello, WebVR! - A-Frame">
    <script src='./aframe-master.js'></script>
    <script src='./three.xr.js'></script>
    <script src='./aframe-xr.js'></script>
    <script src='./hit-test.js'></script>
    <!-- Add MediaPipe libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <style>
      body { margin: 0; overflow: hidden; touch-action: none; }
      video { 
        position: fixed; 
        top: 0; 
        left: 0; 
        width: 100vw; 
        height: 100vh; 
        object-fit: cover;
        opacity: 0; /* Hide video but keep it active */
      }
      canvas#output_canvas { 
        position: fixed; 
        top: 0; 
        left: 0; 
        width: 100vw; 
        height: 100vh;
        pointer-events: none;
        z-index: 999; /* Put hand tracking visualization on top */
        opacity: 0.5; /* Make it semi-transparent */
      }
      .a-canvas {
        z-index: 1;
      }
    </style>
  </head>
  <body>
    <video id="video" autoplay playsinline></video>
    <canvas id="output_canvas"></canvas>
    <a-scene hit-test embedded>
      <a-assets timeout="10000">
        <a-asset-item id="model1" src="./model1.glb"></a-asset-item>
        <a-asset-item id="model2" src="./model2.glb"></a-asset-item>
        <a-asset-item id="model3" src="./model3.glb"></a-asset-item>
        <a-asset-item id="model4" src="./model4.glb"></a-asset-item>
        <a-asset-item id="model5" src="./model5.glb"></a-asset-item>
        <a-asset-item id="model6" src="./model6.glb"></a-asset-item>
        <a-asset-item id="model7" src="./model7.glb"></a-asset-item>
      </a-assets>
      <!-- Add camera entity for AR -->
      <a-entity camera position="0 1.6 0"></a-entity>
    </a-scene>
    <!-- Remove duplicate script tag -->
    <!-- <script src="./hand-tracking.js"></script> -->
    <script>
      var scene = AFRAME.scenes[0];
      var currentModelIndex = 0;
      var currentEntity = null;
      const models = ['#model1', '#model2', '#model3', '#model4', '#model5', '#model6', '#model7'];

      var modelAsset = document.querySelector('#model1');
      modelAsset.addEventListener('error', function(e) {
        console.error('Error loading model:', e);
        createFallbackObject();
      });

      var newObject = function(data) {
        if (currentEntity) {
          scene.removeChild(currentEntity);
        }

        var entity = data.detail;
        entity.setAttribute('gltf-model', models[currentModelIndex]);
        entity.setAttribute('scale', '0.1 0.1 0.1');
        entity.setAttribute('material', {
          shader: 'standard',
          fog: false
        });     

        scene.appendChild(entity);
        currentEntity = entity;
        
        currentModelIndex = (currentModelIndex + 1) % models.length;
      }

      function createFallbackObject(data) {
        if (currentEntity) {
          scene.removeChild(currentEntity);
        }

        var entity = data.detail;
        entity.setAttribute('geometry', {
          primitive: 'box',
          width: 0.1,
          height: 0.1,
          depth: 0.1
        });
        entity.setAttribute('material', {
          color: 'red'
        });
        scene.appendChild(entity);
        currentEntity = entity;
      }

      scene.addEventListener('newAnchoredEntity', newObject);
    </script>
    <script>
      const videoElement = document.getElementById('video');
      const canvasElement = document.getElementById('output_canvas');
      const canvasCtx = canvasElement.getContext('2d');

      let previousLandmarks = null;
      let previousScale = null;
      let previousPosition = null;

      function lerp(a, b, t) {
          return a * (1 - t) + b * t;
      }

      function smoothLandmarks(landmarks) {
          if (!previousLandmarks) {
              previousLandmarks = landmarks;
              return landmarks;
          }

          const smoothedLandmarks = landmarks.map((landmark, index) => {
              const previousLandmark = previousLandmarks[index];
              if (!previousLandmark) return landmark;

              const smoothedX = landmark.x * 0.3 + previousLandmark.x * 0.7;
              const smoothedY = landmark.y * 0.3 + previousLandmark.y * 0.7;
              const smoothedZ = landmark.z * 0.3 + previousLandmark.z * 0.7;

              return { x: smoothedX, y: smoothedY, z: smoothedZ };
          });

          previousLandmarks = smoothedLandmarks;
          return smoothedLandmarks;
      }

      function onResults(results) {
          canvasCtx.save();
          canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
          
          // Draw video with correct size
          canvasCtx.drawImage(
              results.image,
              0, 0, results.image.width, results.image.height,
              0, 0, canvasElement.width, canvasElement.height
          );

          if (results.multiHandLandmarks) {
              for (const landmarks of results.multiHandLandmarks) {
                  const smoothedLandmarks = smoothLandmarks(landmarks);
                  drawConnectors(canvasCtx, smoothedLandmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 5 });
                  drawLandmarks(canvasCtx, smoothedLandmarks, { color: '#FF0000', lineWidth: 2 });

                  if (smoothedLandmarks[8] && smoothedLandmarks[4] && currentEntity) {
                      const indexFinger = smoothedLandmarks[8];
                      const thumb = smoothedLandmarks[4];

                      const distance = Math.sqrt(
                          Math.pow(indexFinger.x - thumb.x, 2) + Math.pow(indexFinger.y - thumb.y, 2)
                      );

                      const targetScale = distance * 5;
                      const smoothedScale = lerp(previousScale || targetScale, targetScale, 0.2);
                      previousScale = smoothedScale;
                      currentEntity.setAttribute('scale', `${smoothedScale} ${smoothedScale} ${smoothedScale}`);

                      const deltaX = thumb.x - indexFinger.x;
                      const deltaY = thumb.y - indexFinger.y;
                      const deltaZ = thumb.z - indexFinger.z;

                      const rotationX = Math.atan2(deltaY, deltaZ) * (180 / Math.PI);
                      const rotationY = Math.atan2(deltaX, deltaZ) * (180 / Math.PI);

                      currentEntity.setAttribute('rotation', `${rotationX} ${rotationY} 0`);
                  }
              }
          }
          canvasCtx.restore();
      }

      function adjustVideoCanvasSize() {
          const width = window.innerWidth;
          const height = window.innerHeight;
          
          // Set canvas size
          canvasElement.style.width = width + 'px';
          canvasElement.style.height = height + 'px';
          canvasElement.width = width;
          canvasElement.height = height;
          
          // Set video size
          videoElement.style.width = width + 'px';
          videoElement.style.height = height + 'px';
          videoElement.width = width;
          videoElement.height = height;
      }

      window.addEventListener('resize', adjustVideoCanvasSize);
      adjustVideoCanvasSize();

      const hands = new Hands({
          locateFile: (file) => {
              return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
          }
      });

      hands.setOptions({
          maxNumHands: 1,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
      });

      hands.onResults(onResults);

      // Modify camera setup
      const camera = new Camera(videoElement, {
          onFrame: async () => {
              await hands.send({ image: videoElement });
          },
          facingMode: "environment",
          width: 1280,
          height: 720
      });

      // Start hand tracking when page loads
      camera.start().catch(error => {
          console.error("Error starting camera:", error);
      });

      // Remove the duplicate camera.start() at the bottom

      // Update status messages
      scene.addEventListener('enter-vr', function () {
          console.log("AR session started");
          statusDiv.textContent = "AR active. Looking for surface...";
          canvasElement.style.opacity = "0.5"; // Show hand tracking overlay
      });

      scene.addEventListener('exit-vr', function () {
          statusDiv.textContent = "AR session ended";
          canvasElement.style.opacity = "0"; // Hide hand tracking overlay
      });

      // Add status indicator
      const statusDiv = document.createElement('div');
      statusDiv.style.position = 'fixed';
      statusDiv.style.bottom = '20px';
      statusDiv.style.left = '20px';
      statusDiv.style.color = 'white';
      statusDiv.style.backgroundColor = 'rgba(0,0,0,0.5)';
      statusDiv.style.padding = '10px';
      statusDiv.style.zIndex = '999';
      document.body.appendChild(statusDiv);

      scene.addEventListener('ar-hit-test-ready', function () {
          console.log("AR hit-test is ready");
          statusDiv.textContent = "Tap to place object. Hand tracking enabled.";
      });

      scene.addEventListener('ar-hit-test-start', function () {
          statusDiv.textContent = "Looking for surface...";
      });

      // Initialize hand tracking immediately
      hands.onResults(onResults);
      camera.start().catch(error => {
          console.error("Error starting camera:", error);
      });
    </script>
  </body>
</html>


